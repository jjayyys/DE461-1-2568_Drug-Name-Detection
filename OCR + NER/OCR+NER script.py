import cv2
import numpy as np
import easyocr
from ultralytics import YOLO
from rapidfuzz import process, fuzz, distance  # Fuzzy Matching and Performance Metrics
from pathlib import Path

# ==========================================
# CONFIGURATION
# ==========================================

# 1. MODEL & IMAGE PATHS
# ------------------------------------------
# Path of best.pt (e.g., 'runs/detect/train/weights/best.pt')
# Use paths relative to this script so it works regardless of current working dir
BASE_DIR = Path(__file__).resolve().parent
print(f"Base Directory: {BASE_DIR}")
# Default model path (adjusted to where models live in this workspace)
MODEL_PATH = str((BASE_DIR.parent / "models" / "YOLOv9t" / "yolov9t_best_model.pt").resolve())

# Default image path (test_images lives next to this script)
IMAGE_PATH = str((BASE_DIR / "test_images" / "PARACETAMOL.jpg").resolve())

# 2. GROUND TRUTH (for Performance Metrics)
# ------------------------------------------
# ‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏î‡∏Ñ‡πà‡∏≤ CER/WER (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏™‡πà ‡∏à‡∏∞‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Metrics)
# ‡πÄ‡∏ä‡πà‡∏ô‡∏ñ‡πâ‡∏≤‡∏†‡∏≤‡∏û‡∏Ñ‡∏∑‡∏≠‡∏¢‡∏≤ Paracetamol ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà "PARACETAMOL"
GROUND_TRUTH = "PARACETAMOL"  # [ACTION REQUIRED] or None

# 3. DATABASE (for NER / Spell Check)
# ------------------------------------------
# Drug Name (Dictionary) for Post-processing
KNOWN_DRUG_NAMES = [
    "PARACETAMOL", "AMLODIPINE", "IBUPROFEN", "CREMAFFIN", 
    "LIPITOR", "NEXIUM", "PLAVIX", "PROPRANOLOL",
    "RISPERDAL", "TYLENOL", "VALPROIC ACID", "ZANTAC", "CYPROHEPTADINE",
    "PROGESTERONE", "ITRACONAZOLE", "CHOLECALCIFEROL"
]

# ==========================================
# 1. SYSTEM SETUP
# ==========================================
# Load EasyOCR (Load once, use many times)
print("Loading OCR Engine...")
reader = easyocr.Reader(['en'], gpu=True) 

# ==========================================
# 2. METRICS CALCULATION (Evaluation)
# ==========================================

def calculate_metrics(prediction, ground_truth):
    """
    Calculate Performance Metrics (OCR Evaluation):
    1. CER (Character Error Rate): ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£
    2. WER (Word Error Rate): ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏≥
    3. Exact Match: ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏õ‡πä‡∏∞‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    4. F1 Score (Character Level): ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
    """
    if not ground_truth:
        return None

    pred_clean = prediction.upper().strip()
    gt_clean = ground_truth.upper().strip()

    # --- 1. Character Error Rate (CER) ---
    # ‡πÉ‡∏ä‡πâ Levenshtein distance ‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡∏Ç‡∏≠‡∏á ground truth
    char_dist = distance.Levenshtein.distance(pred_clean, gt_clean)
    cer = char_dist / max(len(gt_clean), 1)

    # --- 2. Word Error Rate (WER) ---
    pred_words = pred_clean.split()
    gt_words = gt_clean.split()
    # ‡πÉ‡∏ä‡πâ Levenshtein ‡πÅ‡∏ö‡∏ö list (token level) ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏≤ WER
    # (Rapidfuzz ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏°‡∏±‡∏Å‡πÉ‡∏ä‡πâ Logic ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sequence)
    word_dist = distance.Levenshtein.distance(pred_words, gt_words)
    wer = word_dist / max(len(gt_words), 1)

    # --- 3. Exact Match Rate (EMR) ---
    exact_match = 1.0 if pred_clean == gt_clean else 0.0

    # --- 4. F1 Score (Character Level Approximation) ---
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÅ‡∏ö‡∏ö‡∏á‡πà‡∏≤‡∏¢‡∏à‡∏≤‡∏Å LCS (Longest Common Subsequence) ‡∏´‡∏£‡∏∑‡∏≠ Similarity
    # Rapidfuzz ratio ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ 0-100 ‡∏ã‡∏∂‡πà‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ö F1 ‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á Similarity
    similarity = fuzz.ratio(pred_clean, gt_clean) / 100.0
    
    return {
        "CER": cer,
        "WER": wer,
        "Exact_Match": exact_match,
        "Similarity_Score": similarity  # ‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô F1/Accuracy ‡πÉ‡∏ô‡πÄ‡∏ä‡∏¥‡∏á Similarity
    }

# ==========================================
# 3. PREPROCESSING & NER LOGIC
# ==========================================

def preprocess_for_ocr(img_crop):
    """
    Best Practice Preprocessing for OCR:
    Grayscale -> Upscale -> Denoise -> Binarization
    """
    # 1. Convert to Grayscale
    gray = cv2.cvtColor(img_crop, cv2.COLOR_BGR2GRAY)
    
    # 2. Upscaling (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÄ‡∏•‡πá‡∏Å‡∏ö‡∏ô‡∏Ç‡∏ß‡∏î‡∏¢‡∏≤)
    scale_factor = 2
    upscaled = cv2.resize(gray, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)
    
    # 3. Denoising (‡∏•‡∏î‡∏à‡∏∏‡∏î‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢)
    denoised = cv2.fastNlMeansDenoising(upscaled, None, h=10, templateWindowSize=7, searchWindowSize=21)
    
    # 4. Adaptive Thresholding (Binarization)
    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡∏≤‡∏ß-‡∏î‡∏≥ ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤ threshold ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà (‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏ö‡∏ö Global threshold)
    binary = cv2.adaptiveThreshold(
        denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
    )
    
    return binary

def ner_post_processing(ocr_text, db_list, threshold=60):
    """
    NER Correction using Fuzzy Logic:
    ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡∏≥‡∏ú‡∏¥‡∏î‡∏à‡∏≤‡∏Å OCR ‡πÇ‡∏î‡∏¢‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏≤
    """
    if not ocr_text:
        return ocr_text, 0, False

    clean_text = ocr_text.upper().strip()
    
    # ‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô DB
    result = process.extractOne(clean_text, db_list, scorer=fuzz.token_sort_ratio)
    
    if result:
        best_match, score, _ = result
        # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏Å‡∏¥‡∏ô Threshold ‡πÉ‡∏´‡πâ‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
        if score >= threshold:
            return best_match, score, True # True = ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç
            
    return ocr_text, 0, False

# ==========================================
# 4. MAIN PIPELINE
# ==========================================

def main():
    if not MODEL_PATH or not IMAGE_PATH:
        print("‚ùå Error: ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏∞‡∏ö‡∏∏ MODEL_PATH ‡πÅ‡∏•‡∏∞ IMAGE_PATH ‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô Configuration ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏£‡∏±‡∏ô")
        return

    # --- Step 1: Load YOLO Model ---
    print(f"Loading YOLO model from: {MODEL_PATH}")
    model = YOLO(MODEL_PATH)
    
    # --- Step 2: Load Image ---
    image = cv2.imread(IMAGE_PATH)
    if image is None:
        print("‚ùå Error: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Path ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á")
        return
    
    original_h, original_w = image.shape[:2]
    
    # --- Step 3: Inference (Detection) ---
    results = model(image)[0]
    output_image = image.copy()
    
    print(f"\nüîç Found {len(results.boxes)} detections.")
    
    for i, box in enumerate(results.boxes):
        # 3.1 Get Coordinates
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        conf = float(box.conf[0])
        
        # 3.2 Padding (Best Practice)
        # ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Å‡∏£‡∏≠‡∏ö‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ OCR ‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡∏≠‡∏ö‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
        pad = 10
        x1_p = max(0, x1 - pad)
        y1_p = max(0, y1 - pad)
        x2_p = min(original_w, x2 + pad)
        y2_p = min(original_h, y2 + pad)
        
        cropped_img = image[y1_p:y2_p, x1_p:x2_p]
        
        # 3.3 Image Preprocessing
        processed_img = preprocess_for_ocr(cropped_img)
        
        # 3.4 OCR Extraction
        ocr_result = reader.readtext(processed_img, detail=0, paragraph=True)
        raw_text = " ".join(ocr_result)
        
        # 3.5 NER / Correction
        final_text, ner_score, is_corrected = ner_post_processing(raw_text, KNOWN_DRUG_NAMES)
        
        # 3.6 Metrics Evaluation (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Ground Truth)
        metrics_display = ""
        if GROUND_TRUTH:
            metrics = calculate_metrics(final_text, GROUND_TRUTH)
            metrics_display = (f" | CER: {metrics['CER']:.2f}, WER: {metrics['WER']:.2f}, "
                               f"Sim: {metrics['Similarity_Score']:.2f}")
        
        # --- Display Results in Console ---
        print(f"\n--- Detection #{i+1} (Conf: {conf:.2f}) ---")
        print(f"   Original OCR : '{raw_text}'")
        if is_corrected:
            print(f"   NER Corrected: '{final_text}' (Confidence: {ner_score}%)")
        else:
            print(f"   Final Result : '{final_text}'")
            
        if metrics_display:
            print(f"   [Metrics]    : {metrics_display}")
            
        # --- Visualization on Image ---
        # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö
        cv2.rectangle(output_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        
        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (‡∏ñ‡πâ‡∏≤‡πÅ‡∏Å‡πâ NER ‡πÑ‡∏î‡πâ‡πÉ‡∏´‡πâ‡πÇ‡∏ä‡∏ß‡πå‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ)
        label_text = f"{final_text}"
        cv2.putText(output_image, label_text, (x1, y1 - 10), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

    # --- Save Result ---
    output_filename = f"{GROUND_TRUTH}_result.jpg"
    cv2.imwrite(output_filename, output_image)
    print(f"\n‚úÖ Processing Complete. Result saved as '{output_filename}'")

if __name__ == "__main__":
    main()